### 14 ğŸ›ï¸ System-Call Fast-Path on x86-64 Linux

|Step|CPU mode|What happens|Code/structure|
|---|---|---|---|
|â‘  User prepares|CPL=3|PutÂ **syscall #**Â inÂ `RAX`Â + arguments in order:Â `RDI, RSI, RDX, R10, R8, R9`|`asm mov $SYS_write, %eax ; #1`|
|â‘¡Â `syscall`Â instruction|HW microcode raisesÂ **vector 0x80**-like event (but faster thanÂ `int 0x80`) â†’ loads MSRsÂ `STAR/LSTAR/SFMASK`|â€”||
|â‘¢ Entry trampoline (`entry_64.S`Â â†’Â `__do_syscall_64`)|CPLâ†’0,Â `swapgs`, saves volatile GPRs onÂ **per-CPU stack**, disables interrupts (`RFLAGS.IF=0`)|`c struct pt_regs *regs = task_pt_regs(cur);`||
|â‘£ Kernel sys-dispatch|Look upÂ `sys_call_table[rax]`Â (548 entries in v6.2) â†’Â `const sys_call_ptr_t *tbl`|`c long ret = tbl[regs->orig_rax](â€¦);`||
|â‘¤ Work, copy_to/from_user|Scheduler may block here; FPU saved lazily|â€”||
|â‘¥ Return (`sysretq`fast-path)|Restore regs, flip GS, CPL=3, setÂ `RCX,R11`, resume user|Hardware re-enables interrupts perÂ `RFLAGS`Â snapshot||

> **WhyÂ `syscall`Â replacedÂ `int 0x80`**: 1 Âµs â†’ 150 ns typical latency; avoids IDT indirection & legacy privilege checks.

#### 14.1 Minimal inline assembly demo

```c
#include <unistd.h>
#include <stdint.h>

long write1(const char *s, unsigned len) {
    long ret;
    __asm__ volatile (
        "mov  $1, %%rax \n\t"   /* SYS_write */
        "mov  $1, %%rdi \n\t"   /* fd=stdout */
        "syscall        \n\t"
        : "=a"(ret)
        : "S"(s), "d"(len)
        : "rcx","r11","memory");
    return ret;
}
```

---

### 15 ğŸ“¨ Signals â€“ Asynchronous Kernel â†’ Process

```mermaid
sequenceDiagram
  participant HW as NIC
  participant K as Kernel
  participant P as Process (ring3)
  HW->>K: IRQ 42 (packet)
  K->>K: net_rx_softirq()
  K-->>P: set_bit(SIGIO, p->pending)
  Note over P: delivered on next\nreturn to user mode
```

- Delivery point: just beforeÂ `sysret/iret`Â the kernel checksÂ `pending & ~blocked`.
    
- Stack frame pushesÂ **SA_SIGINFO**Â values â†’ user handler runs at user CPL with restorer trampoline.
    

---

### 16 ğŸ“š Function-Pointer Tables in the Kernel

```c
/* include/linux/syscalls.h */
asmlinkage long sys_write(unsigned int, const char __user *, size_t);

/* arch/x86/kernel/syscall_table.S (generated) */
ENTRY(sys_call_table)
 .quad sys_read
 .quad sys_write   /* index 1 */
 .quad sys_open
 ...
END(sys_call_table)
```

ğŸ’¡Â **Exercise**Â (C):

```c
typedef long (*sysfn)(long, long, long);
sysfn tbl[3] = { sys0, sys1, sys2 };
long nr = 1;                 // dynamic â€œraxâ€
long ret = tbl[nr](a,b,c);   // indirect call
```

> _Data-driven dispatch_Â = pointer-chasing overhead vs. massiveÂ `switch`.

---

### 17 ğŸ”„ Context-Switch Internals

#### 17.1 What must be saved?

|Category|Saved?|Rationale|
|---|---|---|
|GPRs (`rax..r15`)|âœ…|user visible|
|SIMD/FPU (XSAVE)|_lazy_|only on first use after switch|
|Segment bases (`fs/gs`)|âœ…|TLS & percpu bases|
|`RIP`Â /Â `RFLAGS`|âœ…|resume point + int-enable bit|
|**Memory**Â pages|âŒ|already isolated by MMU (page tables stay)|

```c
struct thread_struct {
    unsigned long rsp0;     // kernel stack top
    unsigned long cr3;      // page-table root
    struct fpu fpu;         // xsave area
    /* â€¦ */
};
```

#### 17.2 Switching algorithm (LinuxÂ `context_switch()`)

```c
prev->state = TASK_RUNNING;
switch_mm(prev->mm, next->mm, cpu); /* load CR3 if needed */
switch_to(prev, next, &prev);       /* save callee-saved regs, load next */
```

Time cost:Â **~1500 cycles**Â on modern Intel (no SMT) â‰ˆ 700 ns @ 2 GHz.

---

### 18 ğŸ§³ â€œSuitcaseâ€ Model of a Process

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Registers  â”‚  â† context
â”‚  PC/RIP     â”‚
â”‚  Flags      â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  Page table â”‚  â† pointer to full address space
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

_OS moves the suitcase between cores_Â â†’ migration touches:  
`switch_mm()`Â +Â `flush_tlb_other()`Â when NUMA node changes (may cost Âµs).

---

### 19 ğŸ“‰ WhyÂ _Batch_Â Syscalls

Let:

- `t_s`Â = 180 ns syscall entry+exit
    
- payload write per call = 4 B
    
- target throughput = 1 GiB/s
    

```python
calls_per_sec = 1_073_741_824 // 4   # 268M
overhead_sec = calls_per_sec * 180e-9
â‰ˆ 48.2 s !          # impossible
```

Batch at 4 KiB:

```python
calls_per_sec = 1_073_741_824 // 4096  # 262k
overhead â‰ˆ 0.047 s (4.4%)
```

â¡ï¸Â **Always buffer user I/O**Â (glibc does with stdio) and useÂ `writev`,Â `sendmmsg`,Â `io_uring`.

---

### 20 âš–ï¸ Choosing PC vs next-PC on Return

|Trap type|Re-execute current?|Why|
|---|---|---|
|**Page-fault #PF**|âœ…|after page-in the faulting load/store must run again|
|**Syscall/IRQ**|âŒÂ `RIP = next_pc`|instruction already completed|
|**Debug single-step**|depends|#DB may point back to same instr|

Kernel encodes decision inÂ `pt_regs->rip`Â beforeÂ `iret`.

---

### 21 ğŸ” User vs Kernel vs Hypervisor Processes

|Ring|Typical Software|Can runÂ `hlt`?|Access CR3?|
|---|---|---|---|
|0|kernel thread, ksoftirqd|âœ…|âœ…|
|1/2|paravirt guest (rare on x86)|maybe|by VMM policy|
|3|userland, glibc|âŒ (#GP)|âŒ|

> Topâ€™sÂ `PR`Â column showsÂ `R`Â if a task currently occupies a core; hopping amongÂ `CPU`Â column IDs demonstrates OSâ€™s suitcase shuffle.

---

### 22 ğŸ› ï¸ Lab Ideas (continued)

1. **Strace batching**: measureÂ `write()`Â count difference betweenÂ `cat file`Â vsÂ `dd if=file bs=4k`.
    
2. **Kernel ftrace**: tracepointÂ `raw_syscalls:sys_enter`Â to visualise burst -> flush pattern.
    
3. **Write a tiny module**Â exportingÂ `syscall_table`Â pointer, look at entry 17, verify it maps toÂ `sys_nanosleep`.
    

---

### 23 ğŸ“‘ Key Takeaways

- **Syscall**Â = software-raised interrupt; useÂ `syscall`/`sysenter`Â fast paths.
    
- **Signals**Â provideÂ _reverse_Â async channel from kernel to user.
    
- Context consists only ofÂ **register state + PC**; memory isolation via MMU makes save/restore unnecessary.
    
- Scheduler treats each process as aÂ _movable bag_; CPU affinity â‰ˆ cache warmth hint, not correctness rule.
    
- Heavy syscall/IRQ machinery â‡’ design forÂ **amortisation & batching**.
    

---

### 24 ğŸ“ References / Further Study

- Intel SDM vol 3A, ch 6 â€œSystem Programmingâ€.
    
- L. Torvalds,Â _Linux Context Switch Walk-Through_Â (lkml thread).
    
- Ulrich Drepper, â€œWhat Every Programmer Should Know About Memoryâ€, Â§7 context switching.
    
- `arch/x86/entry/entry_64.S`Â &Â `kernel/signal.c`Â in Linux-6.x source.
    

---

_(End of extended notes â€” yell ğŸ§ if you want a drill-down into the scheduler or hyper-privileged VM-exit paths!)_