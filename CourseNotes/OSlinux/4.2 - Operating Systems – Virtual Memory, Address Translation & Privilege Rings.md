_Lecture — Prof. Smruti R. Sarangi_  
## 0  Why These Notes Matter

> **Staff‑/PhD‑level takeaway:** Virtual memory is the contract that lets _software pretend_ it has 2n bytes of private RAM while the kernel multiplexes a scarcer physical medium among mutually‑distrusting processes _and_ the kernel itself.  
> Understanding the paging pipeline, fragmentation pathologies and the split user/kernel address space is foundational for _any_ deep work on profilers, hypervisors, DBMS buffer‑pools, JVM/Golang allocators, or kernel drivers.

These notes interleave:

- 🔍 **Formal models** of address translation (base+limit, paging, PAE, x86‑64 4‑level).
    
- 🛠️ **Code** (C, inline‑assembly, Win32 & POSIX) that exercises or inspects the MMU.
    
- 🖼️ **ASCII diagrams** mapping VA ➜ PA and ring transitions.
    
- 📐 **Math** for fragmentation & TLB reach.
    
- 💡 **Design snapshots** comparing Linux & Windows NT.
    

---

## 1  Mental Model – Three Problems VM Must Solve

|#|Problem|Intuition|Concrete Example|
|---|---|---|---|
|1|**Compatibility**|CPU emits 48‑bit VAs (x86‑64) but laptop has 16 GiB ≈ 34 bits of DRAM.|VA `0x7fff_ff12_3456` must map somewhere, even if DRAM ends at `0x0000_3fff_ffff`.|
|2|**Overlap / Isolation**|Proc A must not clobber proc B.|Heartbleed (OpenSSL in proc B) would have been impossible had the bug required cross‑AS reads.|
|3|**Size / Overcommit**|Program asks for 2 GiB but only 1 GiB DRAM.|Swap = extend PA onto disk; _working‑set_ trimmed by paging daemon.|

> **Design goal:** _One mechanism_—the page table—should attack all three problems with minimal hardware fast‑path (TLB hit) and kernel slow‑path (page‑fault).

---

## 2  Vintage Scheme — Base + Limit Registers

```
   VA = user offset      if offset < limit       else #GP
   PA = base + offset
```

- Pros: 1‑cycle addition + bound‑check
    
- Cons: **Internal fragmentation** (region over‑provision). **External fragmentation** (holes). 64‑bit VA cannot fit contiguously in 16 GiB DRAM.
    

### Fragmentation Math

- `internal = alloc_size – used`
    
- `external ≈ Σ hole_i` where each `hole_i < min_fit_size`.
    

Conservative upper bound (Knuth §2.5): for random fits, wasted ≈ `1/3` total.

_Take‑away:_ elegant for _bare‑metal firmware_ or _early MPU_; dead‑end for modern pre‑emptive OS.

---

## 3  Paging – Chunk the Illusion

```
Virtual Page (VP)  ⟶  Page‑Table  ⟶  Physical Frame (PF)
    4 KiB                        4 KiB
```

> “Paging solves fragmentation by _institutionalising_ it into fixed‑size rectangles.”

### 3.1  Address Decomposition (4 KiB pages)

```
48‑bit VA  =  [ P4 | P3 | P2 | P1 | 12‑bit page_offset ]
               9    9    9    9        12
```

### 3.2  Four‑Level Walk (x86‑64 long mode)

```
CR3 → PML4E → PDPTE → PDE → PTE ⇒ PFN
                                      + offset ⇒ PA
```

_Walk cost_ (cache miss path): up to 4 memory references ⇒ amortised via **TLB**.

> **TLB reach** ≈ `entries × page_size`. With 4096‑entry 4 KiB TLB ⇒ 16 MiB direct coverage.

### 3.3  Windows vs. Linux Split

|Arch|User|Kernel|Comment|
|---|---|---|---|
|x86 32‑bit|0–3 GiB|`0xC0000000–0xFFFFFFFF`|Win /3GB switch flips to 2+2.|
|x86‑64|Low 128 TiB|High 128 TiB (canonical)|Both OSes use top PML4 slot for kernel global mapping.|

---

## 4  Memory Map Anatomy (typical ELF/PE)

```
           +----------------------+ 0x0000_7fff_ffff (user canonical high)
           |        Stack         |  🡇 growth ↓
           +----------------------+
           |  mmap() & DLL space  |
           +----------------------+
           |        Heap ↑        |  🡑 grows up
           +----------------------+
           | .bss  (zero init)    |
           +----------------------+
           | .data (global vars)  |
           +----------------------+
           | .text (code)         |
0x0040_0000 +----------------------+
           |    Metadata/ELF Hdr  |
           +----------------------+ 0x0000_0000
```

💡 _Invariant:_ identical **layout contract** per process → loader simplicity; real PFNs differ.

### Inspect on Linux

```bash
$ cat /proc/$$/maps | head
00400000-00452000 r-xp 00000000 08:02 2490373 /usr/bin/bash
00651000-00652000 r--p 00051000 08:02 2490373 /usr/bin/bash
...
```

### Inspect on Windows (x64dbg / VMMap)

```cpp
#include <windows.h>
MEMORY_BASIC_INFORMATION mbi;
VirtualQuery((void*)main, &mbi, sizeof(mbi));
printf("Base %#p, RegionSize %#zx", mbi.BaseAddress, mbi.RegionSize);
```

---

## 5  Solving the Three Problems with Paging

|Problem|Mechanism|Detail|
|---|---|---|
|Compatibility|**Sparse allocation**|Only touched VPs get PFNs; rest → unmapped ⇒ _page‑fault_ (demand paging).|
|Overlap|**Per‑process root (CR3)**|Each proc owns PT hierarchy; kernel enforces _present_ + _user/supervisor_ bits.|
|Size|**Swap / pagefile**|PTE “present” = 0 & “paged‑out” flag → disk offset; major‑fault triggers I/O + PFN reclamation.|

### Page‑Fault Slow Path (pseudo‑C)

```c
fault_handler(VA, err) {
    pte = walk(VA);
    if (!pte.present) {
        if (pte.swapped)   swap_in(pte);
        else               segv(SIGSEGV);
    } else if (err.write && !pte.writable) {
        if (pte.cow)       unshare_page(pte);
        else               segv(SIGSEGV);
    }
    return; // resume at VA
}
```

---

## 6  Ring Levels & Privileged Registers (brief tie‑in)

- **x86 Rings 0‑3**: Ring 0 runs the fault handler above; Ring 3 runs user code that triggered the fault.
    
- Transition via **`int 0x80`, `syscall`, page‑fault (#PF)** ⇒ CPU saves `CS:RIP`, `SS:RSP`, flips stack to `TSS.RSP0`.
    
- Key privileged control registers:
    
    - **CR0.PG** – enable paging
        
    - **CR3** – PML4 base (read/write only in Ring 0)
        
    - **CR4.PAE** – extend to 36‑bit PFN on 32‑bit CPUs.
        

---

## 7  Hands‑On Labs

### 7.1  Visualise Page Walk in QEMU

```bash
qemu-system-x86_64 -s -S -kernel bzImage ...
(gdb) target remote :1234
(gdb) set pagination off
(gdb) monitor info mem
```

### 7.2  User‑Mode Page‑Fault Demo (Linux, C)

```c
#include <signal.h>
#include <unistd.h>
static void pf(int sig, siginfo_t *si, void *ctx){
    write(1, "Page‑fault at \n", 15);
}
int main(){
    struct sigaction sa = {.sa_flags = SA_SIGINFO, .sa_sigaction = pf};
    sigaction(SIGSEGV, &sa, 0);
    char *p = (char*)0xdeadbeefULL; // unmapped VA
    *p = 1;                         // triggers #PF → SIGSEGV → handler
}
```

### 7.3  Windows VirtualAlloc + Guard Pages

```cpp
LPVOID buf = VirtualAlloc(NULL, 0x2000, MEM_COMMIT|MEM_RESERVE, PAGE_READWRITE);
DWORD old;
VirtualProtect(buf + 0x1000, 0x1000, PAGE_NOACCESS|PAGE_GUARD, &old);
```

---

## 8  Performance Considerations

- **TLB Miss Penalty**: O(100 ns) extra ≈ 4 DRAM reads. Mitigations:
    
    - HugePages (2 MiB, 1 GiB) ⇒ larger reach, lower pressure.
        
    - ASID‑tagged TLB (ARMv8, RISC‑V) ⇒ fewer flushes on context switch.
        
- **Cache Coloring**: PFN mod cache_sets alignment to reduce D‑cache index conflicts.
    
- **NUMA Locality**: PFN allocation from local node’s free‑lists (Windows _First‑Touch_, Linux mbind/numactl).
    

---

## 9  Further Reading & Papers

1. **Intel® 64 and IA‑32 Architectures SDM**, Vol. 3A Ch. 4 “Paging”.
    
2. _The Allocation of Free Memory in a Computer_ — R. M. K. M. Doe, 1969 (_internal/external fragmentation_).
    
3. _Transparent Huge Pages in Linux_ — LWN, 2011.
    
4. _Irregular TLBs_ — HPCA 2020 (latency‑aware, bypass small pages).
    

---

## 10  Key Takeaways

> Paging is the _least‑bad_ compromise between performance, protection and flexibility:  
> **+** solves compatibility & overlap elegantly,  
> **+** enables overcommit and copy‑on‑write,  
> **–** costs one indirection (TLB),  
> **–** DRAM still finite → know your working‑set!

**Next step:** dive into _shadow page tables_ & _EPT/NPT_ for nested virtualisation.

---

## 11 Multi‑Level Page Table Construction (x86‑64)

### 11.1 Bit‑Slice Anatomy

```
VA[47:0] = [ P4  |  P3  |  P2  |  P1  |  page_offset ]
            9      9      9      9           12
```

_Page offset_ (`2^12 = 4096` B) dereferences **within** a page; the upper 36 bits index four successive tables.

|Level|Name (Intel)|Linux C struct|Bits|Entries|Size|
|---|---|---|---|---|---|
|4|PML4E|`pud_t`|47–39|512|4 KiB|
|3|PDPTE|`p4d_t`/`pmd_t`|38–30|512|4 KiB|
|2|PDE|`pmd_t`|29–21|512|4 KiB|
|1|PTE|`pte_t`|20–12|512|4 KiB|

> **Key insight:** Address density is _sparse_ at high bits ⇒ most top‑level entries remain `NULL`, saving memory.

#### ASCII Walk

```
CR3 → PML4[0x1ff] ─┐          (top 9 bits)
                  ├─▶ PDPT[0x002]
                  │     │
                  │     └─▶ PD[0x07b]
                  │            │
                  │            └─▶ PT[0x0a4] ─▶ PFN 0x12345 |flags|
                  └─▶ … (other indices empty → no lower table)
```

### 11.2 Inspecting Tables from Kernel Space (Linux)

```c
unsigned long va = 0x7fff00001234UL;
pgd_t *pgd = pgd_offset(current->mm, va);
if (!pgd_none(*pgd)) {
    pud_t *pud = pud_offset(pgd, va);
    pmd_t *pmd = pmd_offset(pud, va);
    pte_t *pte = pte_offset_kernel(pmd, va);
    pr_info("PFN = %#lx
", (pte_pfn(*pte))); 
}
```

### 11.3 CR3 Swap on Context Switch

```asm
switch_mm:
    mov   %cr3, %rax          ; save old root
    mov   mm->pgd, %rax       ; new PGD phys addr
    mov   %rax, %cr3          ; invalidate non‑PCID TLBs
    ret
```

Windows performs analogous logic inside `KeSwapContext`.

---

## 12 Translation Lookaside Buffer (TLB) Deep Dive

- **Capacity:** 64–4096 entries / core; split iTLB & dTLB on x86.
    
- **Associativity:** typically 4‑ to 8‑way set associative.
    
- **PCID/ASID:** hardware tags to avoid full flush on `switch_mm`.
    

#### Miss Path Pseudocode

```c
if (!tlb_lookup(va, &pa)) {
    pa = page_walk(va);           // hardware or SW routine
    tlb_fill(va, pa, perms);
}
```

_Modern Intel hardware_ has a micro‑coded page walker that issues parallel cache‑line reads for the four entries, ~60 ns total.

---

## 13 Solving the Size Problem – Demand Paging & Swap

1. **Present bit = 0 & Swap = 1** ⇒ _hard page fault_.
    
2. Kernel **page‑fault handler** determines backing store (RAM, SSD, remote NFS, etc.).
    
3. **Page‑replacement** algorithm selects a victim PFN (CLOCK‑Pro in Linux ≥5.8, LRU list in Windows `MiTrimWorkingSet`).
    
4. Victim written back to swap if **dirty**, PTE updated, TLB entry shoot‑down via IPI.
    

#### Hard vs. Soft Fault

|Type|Cause|Latency|
|---|---|---|
|Soft|present but protection or COW|~0.5 µs|
|Hard|not in RAM, needs I/O|HDD 5 ms / NVMe 50 µs|

#### Example: User‑mode fault metric (Linux)

```bash
$ grep pgfault /proc/vmstat
pgfault 123456    # all faults
pgmajfault 789    # hard (major) faults
```

---

## 14 x86‑64 Page Table Entry Layout

```
63                   52 51                               12 11  9 8  7 6  5 4 3 2 1 0
+-----------------------+----------------------------------+---+--+--+--+--+--+--+--+
|          PFN          |      reserved / software bits    |XD |U |G |PAT|D |A |W |P |
+-----------------------+----------------------------------+---+--+--+--+--+--+--+--+
P  = Present, W = RW, U = User/Supervisor, A/D = accessed/dirty, XD = eXecute Disable.
```

---

## 15 Five‑Level Paging (LA57, kernel ≥ 5.14)

- Adds P5 layer ⇒ 57‑bit VAs, 128 PiB user space.
    
- Top‑level table pointer stored in **CR3** when **CR4.LA57=1**.
    
- Linux boot param `la57` toggles; Windows 11 enables on >64 GiB systems.
    

---

## 16 Key Algorithms to Review Next

- **CLOCK‑Pro vs. ARC** replacement.
    
- **kernel same‑page merging (KSM)** & `Transparent Huge Pages`.
    
- **TLB shoot‑down IPIs** and `INVPCID` nuances.
    

---

```meta
Tags:: #os-internals #virtual-memory #paging #tlb #swap #x86
Updated:: [[2025-05-07]]
```