Overview:
- Philosophical discussion on spectral theories in mathematics and deep learning.
- Distinction between complicated and complex systems.
- How deep learning fits into spectral theories and the difference between complicated and complex systems.

Spectral Theories in Mathematics:
- Decompose something complicated into a bunch of individual simple components.
- Two examples: Fourier Transform and Eigen Decomposition (Singular Value Decomposition, SVD).
- Fourier Transform: Decompose a signal into the sum of sine waves (used in signal processing, time series analysis, and image analysis).
- Eigen Decomposition/SVD: A matrix can be represented as the sum of simple rank-one matrices.

Deep Learning and Spectral Theories:
- Deep learning models can be decomposed into simple mathematical operations.
- Each individual unit in deep learning models is implementing a simple operation (dot product and non-linearity).

Complicated vs. Complex Systems:
- Complicated: Lots of parts, but intuitive and understandable (e.g., a car, SVD in linear algebra).
- Complex: Fewer parts, many nonlinearities, unintuitive, hard to predict, and sometimes impossible to understand (e.g., Conway's Game of Life, Lorenz Attractor).

Deep Learning: Simple, Complicated, and Complex:
- Simple: Made up of simple, easy math.
- Complicated: Contains many parts.
- Complex: Many nonlinearities, unintuitive, and difficult to understand.

Keep in mind:
- Consider the concepts of spectral theories, decomposition of systems, and the distinction between complicated and complex systems throughout the course.