Below is a continued extension of the previous Obsidian note. This section adds further insights into output interpretation, weight dynamics, and additional visualizations that deepen your understanding of multi-class classification using the Iris dataset and a fully connected network in PyTorch.

---

## Deep Dive: Analyzing Model Outputs & Weight Dynamics

### Inspecting the Model’s Raw Output and Softmax Transformation

Recall that after a forward pass through the network, we obtain raw outputs (logits) with shape `(150, 3)`, where each row corresponds to one sample and each column to one class. However, these raw values are not probabilities. Applying the softmax function converts these logits into a valid probability distribution. Let’s revisit and extend our inspection.

#### Code: Compare Raw Logits with Softmax Probabilities

```python
# Evaluate the model in inference mode
model.eval()
with torch.no_grad():
    raw_outputs = model(X)  # Shape: (150, 3)
    softmax = nn.Softmax(dim=1)
    probabilities = softmax(raw_outputs)

# Display the first few rows of raw outputs and softmax probabilities
print("Raw outputs (first 5 samples):")
print(raw_outputs[:5])
print("\nSoftmax probabilities (first 5 samples):")
print(probabilities[:5])

# Verify that each row in the softmax output sums to 1
row_sums = probabilities.sum(dim=1)
print("\nSum of probabilities for the first 5 samples:")
print(row_sums[:5])
```

> **Observation:**  
> Although the raw outputs may be positive or negative and span a large range, the softmax transformation scales these values so that each sample’s probabilities sum to one. This is essential for proper interpretation as a probability distribution over classes.

---

### Visualizing Softmax Probabilities Across Samples

A key insight is understanding how confident the model is for each sample and how that confidence varies across the dataset. By plotting the softmax probabilities for each class over the sample indices, you can observe patterns that often correspond to the known order (e.g., the Iris dataset is organized by species).

#### Code: Plotting Class Probabilities per Sample

```python
import numpy as np

# Convert probabilities to a NumPy array for easier plotting
prob_np = probabilities.numpy()

plt.figure(figsize=(10, 6))
for class_idx in range(3):
    plt.plot(prob_np[:, class_idx], 'o', label=f'Class {class_idx}')
plt.xlabel("Sample Index")
plt.ylabel("Probability")
plt.title("Softmax Probabilities for Each Sample")
plt.legend()
plt.show()
```

> **Interpreting the Plot:**  
> - **Distinct Regions:** Because the dataset is ordered (first 1/3 are setosa, next 1/3 versicolor, and last 1/3 virginica), you might see that one class’s probability is very high (close to 1) in its corresponding segment.
> - **Confidence Variation:** Some regions (especially in more challenging classes) might show more uncertainty, where the probabilities are not as peaked. This gives insight into the model’s confidence and potential areas for improvement.

---

### Investigating Weight Dynamics During Training

During training, you may notice that the model’s accuracy seems to plateau and then suddenly improve. This “jump” indicates a period where the weight matrices adjust from suboptimal values to a configuration that better separates the classes.

#### Ideas for Further Investigation

1. **Weight Norm Monitoring:**  
   Track the norm of each weight matrix over epochs to see if there’s a correlation between weight magnitude and model accuracy.

   ```python
   weight_norms = []
   for epoch in range(num_epochs):
       # ... (training loop as before)
       # After the optimizer step, record the norms
       norm_input = model.input_layer.weight.norm().item()
       norm_hidden = model.hidden_layer.weight.norm().item()
       norm_output = model.output_layer.weight.norm().item()
       weight_norms.append((norm_input, norm_hidden, norm_output))
   
   weight_norms = np.array(weight_norms)
   plt.figure(figsize=(10, 4))
   plt.plot(weight_norms[:, 0], label="Input Layer Norm")
   plt.plot(weight_norms[:, 1], label="Hidden Layer Norm")
   plt.plot(weight_norms[:, 2], label="Output Layer Norm")
   plt.xlabel("Epoch")
   plt.ylabel("Weight Norm")
   plt.title("Evolution of Weight Norms During Training")
   plt.legend()
   plt.show()
   ```

2. **Weight Histograms:**  
   Visualize histograms of the weights in a layer before and after training to see how the distribution shifts.

   ```python
   # Visualize weight distribution for the output layer
   weights = model.output_layer.weight.detach().numpy().flatten()
   plt.figure(figsize=(8, 4))
   plt.hist(weights, bins=30, edgecolor='k')
   plt.xlabel("Weight Value")
   plt.ylabel("Frequency")
   plt.title("Histogram of Output Layer Weights")
   plt.show()
   ```

3. **Bias Analysis:**  
   Even though bias parameters are not typically visualized in network diagrams, you can similarly inspect their evolution during training. This is useful for understanding if biases are compensating for features that may not be centered at zero.

---

## Discussion: Training Dynamics & Model Behavior

- **Early Training Behavior:**  
  Initially, the model might be uncertain. The accuracy might hover near chance levels (around 33% for 3 classes) and the loss may decrease gradually.

- **Sudden Improvements:**  
  As training proceeds, a shift in the weight matrices can cause a noticeable jump in accuracy. This “aha” moment occurs when the network finally finds a configuration that effectively separates the classes.

- **Loss vs. Accuracy:**  
  While the loss function tends to decrease smoothly (as it’s a continuous function), the accuracy might show more abrupt changes since it is based on discrete predictions. Monitoring both provides complementary views of training progress.

---

## Next Steps & Further Exploration

1. **Data Shuffling & Splitting:**  
   - In practice, randomize your dataset (or use stratified splits) to avoid biases in training and to better evaluate generalization.

2. **Advanced Architectures:**  
   - Experiment with deeper networks, dropout, or batch normalization to improve model performance.
   - Explore other activation functions or even architectures (e.g., convolutional layers for image data).

3. **Weight Dynamics Exploration:**  
   - As suggested, further analyze weight matrices over training. Techniques such as Principal Component Analysis (PCA) on the weight space or visualizing activations (using t-SNE) can provide deeper insights.

4. **Experiment with Optimizers:**  
   - Try different optimizers (Adam, RMSProp, etc.) and learning rate schedules to see how they affect convergence and final performance.

5. **Interpretability:**  
   - Investigate model interpretability techniques such as saliency maps or SHAP values to understand what features the network deems most important for classification.

---

## Conclusion

In this extended lecture note, we built on our multi-class classification example using the Iris dataset. We detailed the network architecture, walked through the PyTorch implementation, and added advanced visualizations and investigations into the model’s outputs and weight dynamics. These insights form a strong foundation for further exploration in deep learning research.

Keep experimenting with modifications and analyses; the behavior of deep networks often reveals interesting patterns that can inspire new research directions!

---

## References & Further Reading (Extended)

- **In-depth on Weight Initialization & Dynamics:**  
  - Glorot, X., & Bengio, Y. (2010). *Understanding the difficulty of training deep feedforward neural networks.*
- **Interpretability in Deep Learning:**  
  - Montavon, G., Samek, W., & Müller, K.-R. (2018). *Methods for interpreting and understanding deep neural networks.*  
- **Advanced PyTorch Tutorials:**  
  - [PyTorch Official Tutorials](https://pytorch.org/tutorials/)
- **Additional Visualization Techniques:**  
  - [Matplotlib Gallery](https://matplotlib.org/stable/gallery/index.html) – for creative and informative plots.

---

*End of Continued Note*

Feel free to add further sections as you explore the nuances of training dynamics and model interpretation. Happy deep learning!