aliases: [Consensus Algorithm, Paxos, Multi-Paxos, Distributed Consensus]
tags: [Distributed Systems, Concurrency, Consensus, Paxos]
## 1. Introduction
In distributed systems, the words **consensus** and **consistency** often appear together:
- **Consistency**: A broader concept; in distributed systems, it describes *how multiple copies maintain the same state* (e.g., sequential consistency, linearizability).  
- **Consensus**: More specifically refers to *the process* by which multiple nodes **agree on a single value** or outcome (e.g., which operation to perform first in a queue of transactions).

> Reaching a certain consensus doesn't automatically guarantee system-wide consistency, but it is the mechanism that helps achieve consistent states among replicated components.

This article discusses **consensus algorithms**—particularly **Paxos** (and its variant Multi-Paxos)—and how these enable distributed systems to agree on a proposed value or operation while maintaining *safety* and *liveness*.

---
## 2. Consensus in Distributed Systems

### 2.1 The Role of Consensus for Consistency

Modern distributed systems often replicate data across multiple nodes. To maintain the correct order of operations and a uniform state, these nodes must *agree* on certain decisions. Examples:
- **Which transaction** is executed first?
- **What** is the chosen value for a distributed key?
- **Which node** is the current master/leader?

An algorithm that ensures all nodes converge on a single decision is a **consensus algorithm**.

### 2.2 Safety vs. Liveness

Two fundamental properties any consensus algorithm must address:

1. **Safety**: 
   - No two nodes choose different values.
   - Only values proposed by participants can be chosen.
   - Once a value is chosen, it is never overridden.

2. **Liveness**:
   - The system can eventually make a decision; it won't get stuck indefinitely.

Balancing these under partial failures, unreliable networks, and asynchronous conditions is tricky. Paxos is known for guaranteeing safety and liveness under well-defined assumptions.

---

## 3. Paxos

### 3.1 Background & Significance
> “\*There is only one consensus protocol, and that’s Paxos. All others are just broken versions of Paxos.\*”  
> — Mike Burrows (Google Chubby author)

Though somewhat hyperbolic, Paxos (proposed by **Leslie Lamport**, Turing Award laureate and LaTeX inventor) has become a **canonical** approach to distributed consensus. Many other protocols (e.g., Zab, Raft) take ideas from Paxos.

Key references:
- *The Part-Time Parliament* (Lamport, 1990) – original Paxos paper.
- *Paxos Made Simple* (Lamport, 2001) – simpler explanation.

### 3.2 Basic Paxos (Single Paxos)

**Goal**: In a given Paxos instance, the system chooses a **single value** (proposal) among potentially many proposals. Once chosen, the system stays with that value.

#### 3.2.1 Basic Concepts

- **Value**: The operation or data that nodes want to agree upon (e.g., “update row X,” “node Y is new leader,” etc.).
- **Number**: A globally unique, monotonically increasing integer for each proposal (like a timestamp or sequence).
- **Proposal**: `(number, value)` pair.  

**Roles**:
1. **Proposer**: Generates proposals with `(number, value)`, tries to get them accepted.
2. **Acceptor**: Votes on proposals. If more than half accept it, it is “chosen.”
3. **Learner**: Not involved in the decision directly; just learns the final chosen value.

#### 3.2.2 Paxos Constraints

- **C1**: An Acceptor must accept the first proposal it sees (in principle).
- **C2**: A proposal is *chosen* if > half the Acceptors **accept** it (strict majority).
- We want only one final chosen value to avoid inconsistencies.

**Key**: An Acceptor can accept multiple proposals across time, but we rely on a monotonic “proposal number” to ensure no conflicts with earlier decisions.

---

### 3.3 Paxos Algorithm Flow

**Basic Paxos** has two phases:

#### Phase 1: (Prepare / Voting)
1. A **Proposer** picks a new, larger proposal number `n` and sends **prepare(n)** requests to the majority of Acceptors.
2. Each Acceptor, upon receiving **prepare(n)**:
   - If `n` is higher than any proposal number it has responded to before, it promises not to accept any proposals with number < `n`.  
   - It replies with the **highest-numbered** proposal `(n', v')` it has accepted so far (or none if it never accepted anything).

#### Phase 2: (Accept)
1. The Proposer collects responses from > half Acceptors. It sets its proposal’s **value** to the `v'` of the **highest** accepted proposal among these responses (or picks a new value if none responded with an accepted value).
2. Then Proposer sends an **accept(n, v)** request to the same Acceptors.
3. If an Acceptor has not promised anything higher than `n` in the meantime, it **accepts** `(n, v)`.

If > half Acceptors accept `(n, v)`, the proposal is **chosen**. Then:

**Learning**: The system must inform Learners about the chosen value. This can be done in various ways (all Acceptors push to all Learners, or a single “master learner,” etc.).

#### 3.3.1 Correctness Proof Sketch

Lamport’s papers detail a formal proof. Core idea:
- Once a value `v` is chosen with number `n`, any new proposals must incorporate `v` if they see an Acceptor who accepted `(n, v)`. 
- This ensures no second distinct value can be chosen in the same Paxos instance → maintaining *safety*.

### 3.4 Limitations of Basic Paxos
1. Only solves **one**-time consensus for a single value.
2. Requires 2 rounds of network messages per decision (prepare, accept).
3. Multiple Proposers can conflict, causing “livelock.”

---

## 4. Multi-Paxos

### 4.1 Motivation
Many real systems need consensus on a **sequence** of values (like a replicated log of operations). Running Basic Paxos for each “slot” individually would be costly. Also, multiple Proposers can hamper liveness.

### 4.2 Key Ideas
1. **Multiple Paxos Instances**: Each consensus slot is one instance of Basic Paxos. For a series of values (like log entries) we run repeated Paxos instances (one per log index).
2. **Single Chosen Leader**: Only 1 active Proposer (Leader) at a time. This avoids conflicting proposals. The Leader can skip Phase 1 for subsequent slots after it's recognized as stable Leader, reducing overhead to essentially 1 round trip for each new value.

**Leader Election** can itself be done with Paxos. Or in practice, we use a stable node as the Master (like in Google Chubby).

### 4.3 Implementation Examples
- **Google Chubby**: Used Multi-Paxos. Single master for a “session,” extends lease.  
- In multi-slot usage: once a leader is stable, new proposals skip the prepare phase each time, so effectively it’s just “accept requests.” This significantly improves performance.

### 4.4 Paxos vs. 2PC
Where 2PC can block if the coordinator fails, Paxos (Multi-Paxos) provides a fully distributed approach. If one leader fails, a new leader can be elected. Paxos ensures no data inconsistency even under partial failures (except if more than half are down).

---
## 5. Summary & Notes

**Consensus** and **consistency**:
- Consistency is broader, describing the system state among replicas.
- Consensus specifically ensures a single chosen outcome among multiple nodes.

**Paxos**:
- Proposed by Leslie Lamport, widely known standard for achieving distributed consensus robustly.
- Basic Paxos solves a single value’s agreement. Multi-Paxos extends it for multiple values and emphasizes a stable leader to reduce overhead.

**Algorithm Steps**:
1. Prepare/Promise  
2. Accept  
3. Learn  

**Properties**:
- **Safety**: No two values can be chosen.  
- **Liveness**: Should eventually choose a value if enough nodes are up.  

**Practical**:
- In real distributed DB or key-value store, Paxos can manage *replicated logs*, master election, or transaction commit.  
- Multi-Paxos is used in systems like Google Chubby, or other frameworks.  
- Implementations often unify leader election with log replication → bridging into protocols like **Raft** or **Zab**.

**Reading**:
- *Paxos Made Simple* (Lamport, 2001)
- *Paxos Made Live - An Engineering Perspective*  
- *Diego Ongaro’s Paxos vs. Raft* (YouTube Lecture)
---
## Code & Examples

Typical Paxos pseudo-code snippet for Basic Paxos:

```plaintext
function propose(n, v):
    # Phase 1: Prepare
    send "prepare(n)" to majority of Acceptors
    wait for responses
    if not enough responses:
       # no consensus
       return fail
    # pick highest-accepted value if any
    v = highest_accepted_value or v
    # Phase 2: Accept
    send "accept(n, v)" to same Acceptors
    wait for acks
    if majority accept:
       chosen(v)
       notify learners
    else:
       # conflict, new attempt with higher n
```
---
## References & Further Reading

- Leslie Lamport, **The Part-Time Parliament** (Original Paxos Paper, 1990)  
- Leslie Lamport, **Paxos Made Simple** (2001)  
- **Paxos Made Live – An Engineering Perspective** (Google Chubby implementation)  
- [Diego Ongaro’s Paxos vs. Raft Lecture](https://www.youtube.com/)  
- [“Consensus on Transaction Commit” by Lamport et al.](https://lamport.azurewebsites.net/)  
- Discussion of Paxos in [*Designing Data-Intensive Applications*](https://dataintensive.net/)  