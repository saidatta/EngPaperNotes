https://strikefreedom.top/archives/multiple-threaded-network-model-in-redis

---
aliases: [Redis Multithreading, Redis I/O Threads, Network Model, Redis 6.0]
tags: [Redis, Networking, Concurrency, Threading]
creation date: 2021-02-14

> **Author**: Pan Shao  
> **Posted**: 02-14-2021  
> **Last Updated**: 06-06-2024  
> **Views**: 37091  
> **Word Count**: 10805 (~18 minutes reading time)

## 1. Introduction

Redis, as a high-performance in-memory caching system, is primarily a **network server** at its core. One of the essential changes in Redis's evolution has been the move from a purely single-threaded I/O event loop to a **multi-threaded network model** in version 6.0. This article:

1. Explores the background and design of Redis’s **single-threaded** approach.  
2. Shows how **multi-threading** was introduced for big-key deletion in 4.0.  
3. Explains in detail how **I/O multithreading** in 6.0 works for reading/writing clients in parallel.

Along the way, we’ll see code examples and architecture diagrams that clarify how requests are read, parsed, executed, and responded to in a multi-threaded manner.

---

## 2. Recap: Single-Threaded Network Model (Before 6.0)

### 2.1 Single-Threaded Event Loop

Pre-6.0, Redis used a single-threaded, event-driven approach:
- **I/O multiplexing** with `select`, `epoll`, `kqueue` (wrapped in Redis’s `ae.c` event library).
- One thread handles all tasks: accepting connections, reading commands, executing them, writing replies.

**Core handlers**:
- `acceptTcpHandler`: Accept new connections.  
- `readQueryFromClient`: Read & parse commands into `client->querybuf`; then call `processCommand`.  
- **Command Execution**: Single-thread calls the relevant command logic (like `GET`, `SET`, `DEL`...).  
- **Reply**: Data is buffered in `client->buf` or `client->reply`. In `beforeSleep()`, Redis writes responses back to the client via `sendReplyToClient` if needed.

### 2.2 Partial Multithreading in Redis 4.0

Redis 4.0 introduced extra threads for “big key” deletions (`UNLINK`), `FLUSHALL ASYNC`, etc. This avoided blocking the main loop for huge deletion tasks. But **the network path** itself remained single-threaded.

---

## 3. Multi-Threaded I/O in Redis 6.0

As traffic soared, **network I/O** became a bottleneck. Redis 6.0 introduced **I/O threads** to parallelize reading and writing, while **command execution** remains single-threaded. Let’s see the updated architecture:

### 3.1 High-Level Flow

```mermaid
flowchart LR
   A[Client requests command] --> B[Main Thread Event Loop triggers <br> readQueryFromClient]
   B --> C{Check if multi-thread enabled?}
   C -- yes --> D[Put client in clients_pending_read queue]
   C -- no --> E[Do read & parse in main thread as before]
   D --> F[beforeSleep -> handleClientsWithPendingReadsUsingThreads]
   F --> G[Distribute clients to I/O threads]
   G --> H[I/O threads read & parse commands (no exec)]
   H --> I[Main thread waits busy poll]
   I --> J[Main thread executes commands]
   J --> K[Put clients in clients_pending_write queue if replies exist]
   K --> L[beforeSleep -> handleClientsWithPendingWritesUsingThreads]
   L --> M[Distribute clients to I/O threads for writing]
   M --> N[I/O threads write replies to sockets]
   N --> O[Main thread waits busy poll, final checks]
```

**Key difference** vs. single-thread:
- **Reading** commands and **writing** replies can be done in parallel by multiple threads.
- **Command execution** (database access) is still by the main thread.

### 3.2 Code Walkthrough: Reading Requests

1. **`readQueryFromClient(connection *conn)`**:

   ```c
   void readQueryFromClient(connection *conn) {
       client *c = connGetPrivateData(conn);

       // If multi-threading is on, and there's no blocking, enqueue in pending read
       if (postponeClientRead(c)) return;

       // Otherwise, do normal single-threaded read/parse
       ...
   }

   int postponeClientRead(client *c) {
       if (server.io_threads_active &&
           server.io_threads_do_reads &&
           !ProcessingEventsWhileBlocked &&
           !(c->flags & (CLIENT_MASTER|CLIENT_SLAVE|CLIENT_PENDING_READ)))
       {
           c->flags |= CLIENT_PENDING_READ;
           listAddNodeHead(server.clients_pending_read,c);
           return 1;
       } else {
           return 0;
       }
   }
   ```

   - If I/O threading is **enabled** (`server.io_threads_do_reads`), we mark the client `CLIENT_PENDING_READ` and add it to `clients_pending_read` queue. Otherwise, do the old logic inline.

2. **`handleClientsWithPendingReadsUsingThreads()`** in `beforeSleep()`:

   ```c
   int handleClientsWithPendingReadsUsingThreads(void) {
       if (!server.io_threads_active || !server.io_threads_do_reads) return 0;
       int processed = listLength(server.clients_pending_read);
       if (processed == 0) return 0;

       // Distribute clients to IO threads round-robin
       listIter li;
       listNode *ln;
       listRewind(server.clients_pending_read,&li);
       int item_id = 0;
       while((ln = listNext(&li))) {
           client *c = listNodeValue(ln);
           int target_id = item_id % server.io_threads_num;
           listAddNodeTail(io_threads_list[target_id],c);
           item_id++;
       }

       // Indicate we are doing a READ operation
       io_threads_op = IO_THREADS_OP_READ;
       // Set counters for each thread to number of tasks assigned
       for (int j = 1; j < server.io_threads_num; j++) {
           int count = listLength(io_threads_list[j]);
           io_threads_pending[j] = count;
       }

       // The main thread also processes some clients in io_threads_list[0]
       listRewind(io_threads_list[0],&li);
       while((ln = listNext(&li))) {
           client *c = listNodeValue(ln);
           readQueryFromClient(c->conn);
       }
       listEmpty(io_threads_list[0]);

       // Busy poll: wait until all I/O threads have finished
       while(1) {
           unsigned long pending = 0;
           for (int j = 1; j < server.io_threads_num; j++)
               pending += io_threads_pending[j];
           if (pending == 0) break;
       }

       // Now handle the main thread portion: parse commands, etc.
       while(listLength(server.clients_pending_read)) {
           ln = listFirst(server.clients_pending_read);
           client *c = listNodeValue(ln);
           c->flags &= ~CLIENT_PENDING_READ;
           listDelNode(server.clients_pending_read,ln);

           if (c->flags & CLIENT_PENDING_COMMAND) {
               c->flags &= ~CLIENT_PENDING_COMMAND;
               if (processCommandAndResetClient(c) == C_ERR) {
                   continue;
               }
           }
           processInputBuffer(c);

           // If there's output to write, register for pending write
           if (!(c->flags & CLIENT_PENDING_WRITE) && clientHasPendingReplies(c))
               clientInstallWriteHandler(c);
       }

       server.stat_io_reads_processed += processed;
       return processed;
   }
   ```

   - The main thread enumerates `clients_pending_read`.
   - Round-robin assign them to thread lists `io_threads_list[id]`.
   - Set `io_threads_op = IO_THREADS_OP_READ`.
   - Each thread’s `io_threads_pending[j]` is set to the number of assigned clients.
   - The main thread also does some reads in `io_threads_list[0]`.
   - Then **busy poll** until all `io_threads_pending[j]` counters are zero → means all read tasks done.
   - Finally, parse/execute commands in the main thread (`processInputBuffer`).

### 3.3 Code Walkthrough: Writing Responses

After commands are executed, the reply is placed in `client->buf` or `client->reply`. Then:

1. **`handleClientsWithPendingWritesUsingThreads()`** in `beforeSleep()`:

   ```c
   int handleClientsWithPendingWritesUsingThreads(void) {
       int processed = listLength(server.clients_pending_write);
       if (processed == 0) return 0;

       // If too few tasks or only 1 IO thread, do single-threaded writes
       if (server.io_threads_num == 1 || stopThreadedIOIfNeeded()) {
           return handleClientsWithPendingWrites();
       }

       // wake up IO threads if they're sleeping
       if (!server.io_threads_active) startThreadedIO();

       // round-robin distribution
       listIter li;
       listNode *ln;
       listRewind(server.clients_pending_write,&li);
       int item_id = 0;
       while((ln = listNext(&li))) {
           client *c = listNodeValue(ln);
           c->flags &= ~CLIENT_PENDING_WRITE;

           if (c->flags & CLIENT_CLOSE_ASAP) {
               listDelNode(server.clients_pending_write, ln);
               continue;
           }
           int target_id = item_id % server.io_threads_num;
           listAddNodeTail(io_threads_list[target_id],c);
           item_id++;
       }

       io_threads_op = IO_THREADS_OP_WRITE;
       for (int j = 1; j < server.io_threads_num; j++) {
           int count = listLength(io_threads_list[j]);
           io_threads_pending[j] = count;
       }

       // The main thread also writes
       listRewind(io_threads_list[0],&li);
       while((ln = listNext(&li))) {
           client *c = listNodeValue(ln);
           writeToClient(c,0);
       }
       listEmpty(io_threads_list[0]);

       // busy poll for all threads to finish
       while(1) {
           unsigned long pending = 0;
           for (int j = 1; j < server.io_threads_num; j++)
               pending += io_threads_pending[j];
           if (pending == 0) break;
       }

       // check if leftover data remains, register sendReplyToClient if so
       listRewind(server.clients_pending_write,&li);
       while((ln = listNext(&li))) {
           client *c = listNodeValue(ln);
           if (clientHasPendingReplies(c) &&
               connSetWriteHandler(c->conn, sendReplyToClient) == AE_ERR)
           {
               freeClientAsync(c);
           }
       }
       listEmpty(server.clients_pending_write);

       server.stat_io_writes_processed += processed;
       return processed;
   }
   ```

   - If there’s not enough tasks, or only 1 thread, do single-threaded writes.
   - Otherwise, distribute clients across I/O threads.  
   - `io_threads_op = IO_THREADS_OP_WRITE`.  
   - Each thread writes back data to the socket via `writeToClient()`.
   - Main thread busy polls.  
   - If leftover data remains, we register the event handler `sendReplyToClient` for next write-ready.

### 3.4 I/O Thread Main Loop

```c
void *IOThreadMain(void *myid) {
    long id = (unsigned long)myid;
    redis_set_thread_title("io_thd_%ld", id);
    redisSetCpuAffinity(server.server_cpulist);
    makeThreadKillable();

    while(1) {
        // Busy polling for tasks
        for (int j = 0; j < 1000000; j++) {
            if (io_threads_pending[id] != 0) break;
        }
        if (io_threads_pending[id] == 0) {
            // Sleep if still no tasks
            pthread_mutex_lock(&io_threads_mutex[id]);
            pthread_mutex_unlock(&io_threads_mutex[id]);
            continue;
        }

        // tasks found
        listIter li;
        listNode *ln;
        listRewind(io_threads_list[id],&li);
        while((ln = listNext(&li))) {
            client *c = listNodeValue(ln);
            if (io_threads_op == IO_THREADS_OP_WRITE) {
                writeToClient(c,0);
            } else if (io_threads_op == IO_THREADS_OP_READ) {
                readQueryFromClient(c->conn);
            } else {
                serverPanic("io_threads_op unknown");
            }
        }
        listEmpty(io_threads_list[id]);
        io_threads_pending[id] = 0; // done
    }
}
```

- Each thread is pinned to a CPU core if configured (`redisSetCpuAffinity`).
- Waits in a **spin loop** up to 1 million iterations; if still no tasks, tries to lock → sleep until woken by main thread’s `startThreadedIO`.
- Process assigned tasks from `io_threads_list[id]`.
- For **WRITE**: `writeToClient()`.
- For **READ**: `readQueryFromClient()`, but only partial parse (no command execution).
- Set `io_threads_pending[id] = 0` to signal completion.

### 3.5 Lock-Free Implementation

Though multiple threads are used, we see no big data structure locks. Instead:
- An **atomic** counter `io_threads_pending[id]`.
- The task queue `io_threads_list[id]` is accessed only by the main thread *before* waking the I/O thread, and only by the I/O thread *during* the processing. So it’s “interleaved” ownership, no overlap.  
- The main thread uses a busy poll to see if `io_threads_pending[j] == 0` for each thread j.

Hence, concurrency is minimized to keep code simpler. Redis’s data store remains single-thread accessed.

---

## 11. Performance Improvements

The I/O threads approach can roughly **double** the throughput for network-bound workloads, as shown by official and third-party benchmarks. E.g., at high concurrency (lots of client connections), the read/write overhead is distributed across multiple cores.

---

## 12. Model Limitations

1. **Not** a full multi-reactor design. Command execution is still single-threaded.  
2. The main thread must “**busy poll**” for I/O thread completion. This is somewhat crude, spinning and locking.  
3. Potential improvements: more advanced synchronization or truly parallel command execution would require major data structure reworks (thread-safety for all Redis structures).

Despite these limitations, it’s a **compromise** to preserve simplicity and maintain backward compatibility, while letting Redis harness multi-core CPU for I/O tasks.

---

## 13. Conclusion

Redis’s journey from a single-threaded event loop to a **multi-threaded** I/O model in 6.0 reveals the complexity of concurrency design in a database/caching system. The final architecture:

- **Main Thread**: Accept connections, orchestrate tasks, execute commands.  
- **I/O Threads**: Read requests into buffers, parse partial commands, and write responses.  
- **Single-thread** for actual command execution, no need for locks on data structures.  
- **Lock-free** concurrency via atomic counters + “interleaved” queue access.  
- Gains **performance** for I/O-heavy scenarios on multi-core machines.

**Key Takeaway**: 
> The Redis 6.0 multi-threaded approach is a pragmatic compromise to improve I/O throughput without rewriting the entire data store for concurrency.

---

## References & Further Reading

1. **Redis 6.0** [Release Notes](https://raw.githubusercontent.com/redis/redis/6.0/00-RELEASENOTES).  
2. [Redis Official Documentation](https://redis.io/docs/)  
3. [Redis Source Code on GitHub](https://github.com/redis/redis)  
4. [Lazy Redis is better Redis (Antirez Blog)](http://antirez.com/news/)  
5. [Benchmarking the Experimental Redis Multi-Threaded I/O](https://www.monterail.com/blog/benchmarking-redis-multi-threaded-io)  
6. [NUMA Deep Dive Part 1: From UMA to NUMA](https://engineering.facile.it/blog/eng/numa-deep-dive-part-1/)  

```