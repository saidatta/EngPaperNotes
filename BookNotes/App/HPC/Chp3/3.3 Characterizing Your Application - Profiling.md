https://learning.oreilly.com/library/view/parallel-and-high/9781617296468/OEBPS/Text/ch03_Robey.htm#sigil_toc_id_58
### Overview
This section covers:
- Understanding the performance characteristics of your application.
- Developing insights into how different subroutines and functions depend on each other.
- Identifying hot spots in your code for parallelization.
Profiling is essential to uncover performance bottlenecks and determine where optimization efforts will have the highest impact.
### Example: Profiling the Krakatau Tsunami Wave Simulation
To profile the wave simulation application:
- We compare the serial version to the parallel versions (with OpenMP and vectorization) using the CloverLeaf mini-app as a reference.
- CloverLeaf solves compressible fluid dynamics equations, similar to the equations used in the wave simulation, making it a useful benchmark.

### 3.3.1 Profiling Tools

Profiling tools help identify where your application spends most of its time (hot spots) and how its subroutines interact with each other. We will explore tools like **Valgrind's Cachegrind**, **Intel Advisor**, and **Likwid** for their high-level overviews and detailed call graphs.

#### Key Profiling Goals

- **Identify Hot Spots**: Find the routines consuming the most computation time.
- **Analyze Dependencies**: Understand the call hierarchy to identify independent tasks.
- **Performance Planning**: Use insights to decide where to parallelize code.

### Using Call Graphs for Hot-Spot and Dependency Analysis

Call graphs visualize the execution flow of a program, showing which subroutines call each other and how much time they consume. This helps identify the most computationally expensive routines.
#### Exercise: Generating a Call Graph using Cachegrind
To generate and visualize call graphs:
1. **Install Valgrind and QCacheGrind**
    ```bash
sudo apt-get install valgrind kcachegrind
```
2. **Download and Build CloverLeaf**:
    ```bash
    git clone --recursive https://github.com/UK-MAC/CloverLeaf.git cd CloverLeaf/CloverLeaf_Serial make COMPILER=GNU IEEE=1 C_OPTIONS="-g -fno-tree-vectorize" OPTIONS="-g -fno-tree-vectorize"
    ```
3. **Run the Callgrind Tool**:
```bash
	valgrind --tool=callgrind ./clover_leaf
```
    
4. **Visualize the Call Graph**:
```bash
    qcachegrind callgrind.out.<process_id>
```
### Call Graph Example: CloverLeaf Visualization

The call graph generated by QCacheGrind will display the percentage of time consumed by each function at each level of the call stack. This information highlights the computational hot spots that require optimization.

sql

Copy code

`+---------------------------------------------------+ | Kernel               | % Time | Calls            | |---------------------------------------------------| | main                 | 100%   | 1               | | ├── advection        | 68%    | 10,000          | | └── update_energy    | 32%    | 5,000           | +---------------------------------------------------+`

In this example, the **advection** routine is the most time-consuming operation, indicating a prime candidate for optimization.

### Intel® Advisor: Roofline Analysis

Intel® Advisor integrates a roofline model to identify bottlenecks between compute and memory operations. It helps determine whether the code is **compute-bound** or **memory-bound**.

#### Exercise: Roofline Analysis with Intel Advisor

1. **Build OpenMP Version of CloverLeaf**:
    
    bash
    
    Copy code
    
    `git clone --recursive https://github.com/UK-MAC/CloverLeaf.git cd CloverLeaf/CloverLeaf_OpenMP make COMPILER=INTEL IEEE=1 C_OPTIONS="-g -xHost" OPTIONS="-g -xHost"`
    
2. **Run Roofline Analysis**:
    
    bash
    
    Copy code
    
    `advixe-cl --collect roofline --project-dir ./advixe_proj -- ./clover_leaf advixe-gui`
    

The roofline plot shows the performance of kernels relative to theoretical limits, with each kernel's location indicating whether it is compute-bound or memory-bound.

### Example: Roofline Plot Analysis

The **roofline plot** helps visualize performance bottlenecks:

- **Horizontal lines** indicate compute-bound regions.
- **Sloped lines** show memory-bound regions.

Kernels located far from the horizontal compute-bound line have potential for increased performance through parallelism and vectorization.

### Using Likwid for Profiling

**Likwid** provides detailed hardware performance data, including memory bandwidth and computational rates, using the system's machine-specific registers (MSR).

#### Exercise: Likwid Performance Measurement

1. **Install Likwid**:
    
    bash
    
    Copy code
    
    `git clone https://github.com/RRZE-HPC/likwid.git cd likwid make sudo make install sudo modprobe msr`
    
2. **Run Likwid for CloverLeaf**:
    
    bash
    
    Copy code
    
    `likwid-perfctr -C 0-87 -g MEM_DP ./clover_leaf`
    

This command measures metrics like **arithmetic intensity**, **FLOPs/byte**, and **energy consumption** for the application.

#### Rust Code Example: Estimating FLOPs using Likwid Data

rust

Copy code

`fn calculate_arithmetic_intensity(flops: f64, memory_ops: f64) -> f64 {     flops / memory_ops }  fn main() {     let intensity = calculate_arithmetic_intensity(41274.0, 123319.9692);     println!("Arithmetic Intensity: {:.2} FLOPs/byte", intensity); }`

### 3.3.2 Measuring Processor Clock Frequency and Energy Consumption

Processors adjust their frequency dynamically, influencing performance and energy efficiency. Tools like **likwid-powermeter** and **Intel Power Gadget** allow tracking of these metrics.

#### Interactive Command for Monitoring Clock Frequency

bash

Copy code

`watch -n 1 "lscpu | grep MHz"`

This command dynamically updates the clock frequency every second.

### 3.3.3 Tracking Memory Usage in Real-Time

Understanding memory consumption is critical for optimizing performance, especially in large-scale parallel applications.

#### Command-Line Tools for Monitoring Memory Usage

- **Using `watch` with `/proc`**:
    
    bash
    
    Copy code
    
    `watch -n 1 "grep VmRSS /proc/<pid>/status"`
    

### Inserting Markers for Performance Analysis with Likwid

Markers allow detailed analysis of specific code sections by measuring their performance separately.

#### Code Example: Integrating Likwid Markers into Rust

rust

Copy code

`extern crate likwid;  // Assuming a binding to Likwid's C library  fn main() {     likwid::marker_init();     likwid::marker_start("Compute");          // Your compute-intensive code here      likwid::marker_stop("Compute");     likwid::marker_close(); }`

### Jupyter Notebooks for Roofline Plotting

**Charlene Yang's Roofline Plotting Tool** allows easy generation of high-quality roofline plots using Python and Jupyter.

#### Exercise: Creating a Roofline Plot with Jupyter

1. **Install Required Libraries**:
    
    bash
    
    Copy code
    
    `pip install numpy scipy matplotlib jupyter`
    
2. **Run Jupyter Notebook**:
    
    bash
    
    Copy code
    
    `jupyter notebook HardwarePlatformCharacterization.ipynb`
    

### Summary

- **Profiling tools** like Cachegrind, Intel Advisor, and Likwid are critical for identifying performance bottlenecks.
- **Roofline analysis** helps determine whether an application is compute-bound or memory-bound.
- Tools like **Likwid** and **Intel Power Gadget** offer valuable insights into processor frequency, energy consumption, and memory performance.
- Using these insights, you can optimize your code for parallelism, improving both performance and efficiency.