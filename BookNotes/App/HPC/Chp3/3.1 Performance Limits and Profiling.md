https://learning.oreilly.com/library/view/parallel-and-high/9781617296468/OEBPS/Text/ch03_Robey.htm#sigil_toc_id_47
### Chapter Overview
This chapter covers:
- **Understanding application performance limits**
- **Evaluating hardware performance capabilities**
- **Measuring the current performance of your application**
Properly profiling your application and understanding the hardware's capabilities help identify where optimizations will have the greatest impact. Profiling also provides insight into how efficiently your application uses the underlying hardware.
### 3.1 Understanding Potential Performance Limits
#### Hardware Performance Limits
Modern computational systems have various performance limits, which can be broadly categorized into two types:
- **Speeds (how fast)**: Refers to the rate at which operations (FLOPs, instructions) can be performed.
- **Feeds (how much data)**: Relates to memory, disk, and network bandwidth.
Common performance limits:
1. **Floating-point operations (FLOPs)**
2. **General operations (Ops)**
3. **Memory bandwidth**
4. **Memory latency**
5. **Instruction queue/cache**
6. **Network bandwidth**
7. **Disk bandwidth**
These factors can be classified as either **latency-bound** (time to fetch first data) or **bandwidth-bound** (rate of data transfer).

**Key Equation for Memory Bandwidth:**
\[
\text{Non-contiguous Bandwidth (B_{nc})} = U_{\text{cache}} \times B_{E}
\]
Where:
- \(U_{\text{cache}}\) = Average percentage of cache used
- \(B_{E}\) = Empirical bandwidth

#### Arithmetic Intensity and Machine Balance
- **Arithmetic Intensity (AI)**: Ratio of FLOPs to memory operations.
    \[
    \text{AI} = \frac{\text{FLOPs}}{\text{Memory Operations}}
    \]
- **Machine Balance (MB)**: Ratio of achievable FLOPs to memory bandwidth.
    \[
    \text{MB} = \frac{\text{FLOPs}}{\text{Memory Bandwidth}}
    \]

Applications with high arithmetic intensity tend to be computation-bound, while those with low intensity are more likely to be bandwidth-bound.
### 3.2 Determining Hardware Capabilities: Benchmarking
Understanding your hardware's performance is crucial for developing high-performance parallel applications. This section focuses on conceptual models and empirical measurements to understand system capabilities.
#### Tools for System Characterization
Tools like **lstopo**, **lscpu**, and **lspci** can provide detailed insights into your system's architecture and capabilities.
- **lstopo**: Visualizes the hardware topology, including CPU cores, caches, and interconnects.
- **lscpu**: Displays CPU architecture details, cache sizes, and available instruction sets.
- **lspci**: Lists PCI devices, including GPUs, on your system.
### Example: Profiling with `lscpu` on a Linux System
```bash
$ lscpu
```
Sample output:
```
Model name:          Intel(R) Core(TM) i5-6500 CPU @ 3.20GHz
CPU MHz:             3192.000
CPU cores:           4
Flags:               sse4_1, sse4_2, avx2
```
The flags indicate support for vector instructions like SSE and AVX2, which are crucial for high-performance SIMD operations.
#### Calculating Theoretical Maximum FLOPs
To estimate the peak FLOPs for a processor, we use the following formula:
\[
F_T = C_v \times f_c \times I_c
\]
Where:
- \(C_v\) = Number of virtual cores (physical cores \(\times\) hyperthreads)
- \(f_c\) = Clock rate in GHz
- \(I_c\) = Instructions per cycle

For a processor with 8 virtual cores, 3.7 GHz clock speed, and 8 FLOPs/cycle:
\[
F_T = 8 \times 3.7 \, \text{GHz} \times 8 = 236.8 \, \text{GFlops/s}
\]

### Rust Code Example: Calculating Theoretical FLOPs
```rust
fn calculate_flops(virtual_cores: u32, clock_rate: f64, flops_per_cycle: u32) -> f64 {
    virtual_cores as f64 * clock_rate * flops_per_cycle as f64
}

fn main() {
    let flops = calculate_flops(8, 3.7, 8);
    println!("Theoretical FLOPs: {:.2} GFlops/s", flops);
}
```
### 3.2.3 Memory Hierarchy and Bandwidth
Memory hierarchy significantly impacts the performance of computational applications. Data moves through multiple levels of cache before reaching the processor.
#### Theoretical Memory Bandwidth Calculation
\[
B_T = MTR \times M_c \times T_w \times N_s
\]
Where:
- \(MTR\) = Memory transfer rate
- \(M_c\) = Number of memory channels
- \(T_w\) = Transfer width (8 bytes)
- \(N_s\) = Number of sockets

Example for LPDDR3-2133 memory with two channels:
\[
B_T = 2133 \times 2 \times 8 \times 1 = 34.1 \, \text{GiB/s}
\]

#### Empirical Measurement Using STREAM Benchmark
The STREAM Benchmark measures the actual bandwidth of your system by performing operations like copy, scale, add, and triad.

```bash
# Clone STREAM Benchmark and compile
git clone https://github.com/jeffhammond/STREAM.git
cd STREAM
make stream_c.exe
./stream_c.exe
```
### 3.2.4 Roofline Model Analysis
The roofline model visually represents the relationship between arithmetic intensity and achievable FLOPs. The model illustrates how bandwidth and compute limits affect performance.
- **Vertical axis**: FLOPs/sec
- **Horizontal axis**: Arithmetic intensity
- **Sloped line**: Represents bandwidth limits
- **Horizontal line**: Represents FLOP limits
This plot helps identify whether an application is compute-bound or memory-bound.
### Rust Code Example: Arithmetic Intensity Calculation
```rust
fn arithmetic_intensity(flops: f64, memory_ops: f64) -> f64 {
    flops / memory_ops
}

fn main() {
    let ai = arithmetic_intensity(1e9, 1e8);
    println!("Arithmetic Intensity: {:.2} FLOPs per byte", ai);
}
```

### 3.2.5 Calculating Machine Balance
**Theoretical Machine Balance:**
\[
MB_T = \frac{F_T}{B_T}
\]
Example:
\[
MB_T = \frac{236.8 \, \text{GFlops/s}}{34.1 \, \text{GiB/s} \times 8} \approx 56 \, \text{Flops/word}
\]

**Empirical Machine Balance:**
\[
MB_E = \frac{F_E}{B_E}
\]

### Summary
- **Profiling** is essential to identify bottlenecks and maximize parallel performance.
- **Machine balance** and **arithmetic intensity** help categorize applications as compute-bound or memory-bound.
- Use tools like STREAM Benchmark and Roofline Model to empirically measure your system's capabilities.

### Exercises
1. **Calculate the empirical bandwidth** of your system using the STREAM benchmark.
2. **Determine the machine balance** for both theoretical and empirical values.
3. **Visualize performance limits** using the Roofline model for a CPU or GPU.

These detailed analyses guide your efforts in high-performance computing to ensure that resources are focused where they deliver the most significant speedup.