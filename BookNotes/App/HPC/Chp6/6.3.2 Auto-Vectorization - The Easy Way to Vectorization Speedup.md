### **Overview**
Auto-vectorization is one of the simplest and most effective methods to boost performance using vectorization techniques. It allows compilers to automatically transform loops and other code structures into vectorized instructions without manual intervention from the developer. This note covers the principles of auto-vectorization, how to guide the compiler to make the most of it, and how to verify its performance impact using tools.

### **Definition**
**Auto-vectorization** is the process by which a compiler automatically converts scalar code into vector operations, leveraging SIMD (Single Instruction, Multiple Data) architecture to process multiple data points in parallel.

### **How Auto-Vectorization Works**
Auto-vectorization typically occurs when compilers detect loops or repetitive operations that can be executed in parallel. Compilers like GCC, Clang, and Intel's ICC automatically try to generate SIMD instructions that can handle multiple data elements at once.

#### **Example: Auto-Vectorization of STREAM Triad Benchmark**
The STREAM Triad benchmark is a common test used to measure memory bandwidth in high-performance systems. Here is a C example demonstrating how auto-vectorization works with the STREAM Triad:

```c
#include <stdio.h>
#include <sys/time.h>

#define NTIMES 16
#define STREAM_ARRAY_SIZE 80000000

static double a[STREAM_ARRAY_SIZE], b[STREAM_ARRAY_SIZE], c[STREAM_ARRAY_SIZE];

int main() {
    double scalar = 3.0, time_sum = 0.0;
    for (int i = 0; i < STREAM_ARRAY_SIZE; i++) {
        a[i] = 1.0;
        b[i] = 2.0;
    }

    for (int k = 0; k < NTIMES; k++) {
        struct timeval tstart;
        gettimeofday(&tstart, NULL);
        for (int i = 0; i < STREAM_ARRAY_SIZE; i++) {
            c[i] = a[i] + scalar * b[i];
        }
        struct timeval tend;
        gettimeofday(&tend, NULL);
        time_sum += (tend.tv_sec - tstart.tv_sec) * 1e3 + (tend.tv_usec - tstart.tv_usec) * 1e-3;
    }

    printf("Average runtime is %lf msecs\n", time_sum / NTIMES);
    return 0;
}
```

### **Compiler Flags for Auto-Vectorization**
To enable auto-vectorization and maximize its benefits, use appropriate compiler flags:
- **GCC/Clang**: `-O3 -ftree-vectorize -march=native -fopt-info-vec-optimized`
- **Intel Compiler**: `-xHost -O3 -vec-report3`

The `-fopt-info-vec-optimized` flag will provide detailed feedback on which loops were vectorized.

#### **Sample Compiler Feedback for Vectorized Loop**
After compiling the code, you may see feedback like:
```
stream_triad.c:19:7: note: loop vectorized
stream_triad.c:12:4: note: loop vectorized
```
This output indicates that the compiler successfully vectorized both the initialization loop and the stream triad loop.

### **Verifying Auto-Vectorization Using Tools**
To confirm that your code is being vectorized as expected, you can use performance analysis tools like **likwid**:
```bash
likwid-perfctr -C 0 -f -g MEM_DP ./stream_triad
```

The output might include:
```
| FP_ARITH_INST_RETIRED_256B_PACKED_DOUBLE |   PMC2  |  640000000 |
```
This line indicates that 256-bit packed double operations were used, confirming vectorized execution.

---

## **6.3.3 Teaching the Compiler Through Hints: Pragmas and Directives**

### **Using Pragmas for Explicit Vectorization**
If the compiler fails to auto-vectorize a loop, you can use **pragmas** to guide it. A pragma is a compiler directive that provides additional information about how to process code.

#### **Example: Vectorizing with Pragmas**
```c
#pragma omp simd reduction(+:sum)
for (int i = 0; i < n; i++) {
    sum += array[i];
}
```
In this example, `#pragma omp simd` tells the compiler to apply SIMD (Single Instruction, Multiple Data) optimizations to the loop.

### **Benefits of Using `restrict` Keyword**
Using the `restrict` keyword assures the compiler that pointers do not overlap, which helps with more aggressive optimizations.

```c
void vector_add(double* restrict a, double* restrict b, double* restrict c, int n) {
    for (int i = 0; i < n; i++) {
        c[i] = a[i] + b[i];
    }
}
```
This code promises the compiler that `a`, `b`, and `c` point to separate memory areas, enabling better vectorization.

---

## **6.3.4 Vector Intrinsics for Fine-Grained Control**

When auto-vectorization and pragmas are insufficient, **vector intrinsics** allow direct control over SIMD operations. These low-level functions map directly to machine instructions, providing the highest level of control for vectorization.

### **Example: Vectorizing a Kahan Sum Using Rust Intrinsics**
Using Rustâ€™s SIMD support through `std::arch`, here is an implementation of the Kahan summation with intrinsics:

```rust
use std::arch::x86_64::*;

unsafe fn kahan_sum(arr: &[f64]) -> f64 {
    let mut sum = _mm256_setzero_pd(); // Initialize sum as a vector of zeros
    let mut compensation = _mm256_setzero_pd(); // Initialize compensation for error correction

    for i in (0..arr.len()).step_by(4) {
        let vec = _mm256_loadu_pd(&arr[i] as *const f64); // Load four elements
        let corrected = _mm256_add_pd(vec, compensation);
        let new_sum = _mm256_add_pd(sum, corrected);
        compensation = _mm256_sub_pd(corrected, _mm256_sub_pd(new_sum, sum));
        sum = new_sum;
    }

    // Horizontal sum to convert vector sum to scalar
    let sum_arr: [f64; 4] = std::mem::transmute(sum);
    sum_arr.iter().sum()
}

fn main() {
    let data = vec![1.0; 8];
    let result = unsafe { kahan_sum(&data) };
    println!("Kahan sum result: {}", result);
}
```
This implementation demonstrates vectorized error correction using SIMD, improving numerical stability with minimal overhead.

---

## **6.3.5 Understanding Vector Assembly Instructions**

For the most granular control, you can directly inspect and manipulate assembly instructions generated by the compiler. This requires a deep understanding of hardware architecture but can offer maximum performance.

### **Viewing Assembly Code**
To view the assembly instructions for your compiled code, use:
```bash
objdump -d -M=intel --no-show-raw-insn your_code.o
```
This will output the assembly, allowing you to confirm that vector instructions (`ymm`, `zmm` registers) are used.

### **Analyzing Vector Instructions Example**
```
18:   vmovapd %ymm0,%ymm1
1c:   vaddpd %ymm2,%ymm0,%ymm0
20:   vaddpd (%rdi,%rax,8),%ymm2,%ymm3
```
The presence of `vaddpd` (vector addition) confirms SIMD instructions are in use, validating the vectorization process.

---

## **Performance Insights**

### **Understanding Speedup with Vectorization**
The potential speedup from vectorization is determined by:
\[ \text{Speedup} = \frac{\text{Number of Scalar Instructions}}{\text{Number of Vector Instructions}} \times \text{Vector Length} \]

#### **Example Calculation**
- Assume a scalar loop takes 100 instructions, reduced to 25 with a 4-lane SIMD unit.
- Speedup = \( \frac{100}{25} \times 4 = 16 \).

This suggests a theoretical 16x improvement, but actual performance depends on memory bandwidth and data alignment.

### **Performance Considerations**
- **Data Alignment**: Align data to 32 or 64-byte boundaries.
- **Cache Utilization**: Ensure data fits within CPU cache levels to minimize latency.
- **Minimize Dependencies**: Avoid dependencies that stall SIMD pipelines.

### **ASCII Visualization of SIMD Execution**
```
| SIMD Vector Execution: Processing 4 Elements Simultaneously     |
|----------------------------------------------------------------|
| [a1, a2, a3, a4] + [b1, b2, b3, b4] -> [c1, c2, c3, c4]       |
|----------------------------------------------------------------|
```

---

## **Summary**

Auto-vectorization is an invaluable technique in high-performance computing, allowing compilers to leverage SIMD capabilities with minimal programmer effort. By using the right compiler flags, pragmas, and the `restrict` keyword, you can guide the compiler to generate efficient vectorized code. For cases where auto-vectorization fails, using vector intrinsics and direct assembly instructions provides the control needed to harness the full power of modern CPUs.

These techniques are crucial for achieving optimal performance in applications bound by computational throughput, ensuring you make the most of every FLOP available on your hardware.