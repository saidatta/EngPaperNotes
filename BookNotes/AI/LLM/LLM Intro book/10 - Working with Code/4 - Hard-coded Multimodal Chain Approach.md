# Staff+ Obsidian Notes: Hard-coded Multimodal Chain Approach with SequentialChain

## Overview
This approach illustrates how to build a multimodal application called **StoryScribe**, which accomplishes the following:
- **Generates a story based on a topic.**
- **Creates a social media post to promote the story.**
- **Generates an accompanying image.**

### Implementation Strategy
Unlike agentic methods that rely on LLM agents to decide the execution path, the hard-coded approach uses **SequentialChain** in LangChain. This type of chain explicitly defines the order of execution and facilitates control over the process flow.

## Steps to Implement StoryScribe

### Step 1: Initialize the Story Generator Chain
- **Purpose**: Generate a story based on user-defined topic, genre, and target audience.

**Code Example**:
```python
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

story_template = """You are a storyteller. Given a topic, a genre and a target audience, you generate a story.
Topic: {topic}
Genre: {genre}
Audience: {audience}
Story: This is a story about the above topic, with the above genre and for the above audience:"""

story_prompt_template = PromptTemplate(input_variables=["topic", "genre", "audience"], template=story_template)
story_chain = LLMChain(llm=llm, prompt=story_prompt_template, output_key="story")

result = story_chain({'topic': 'friendship story', 'genre': 'adventure', 'audience': 'young adults'})
print(result['story'])
```

**Sample Output**:
```plaintext
"John and Sarah had been best friends since they were kids. They had grown up together, shared secrets, and been through thick and thin..."
```

### Step 2: Initialize the Social Media Post Generator Chain
- **Purpose**: Generate a social media post promoting the generated story in a platform-specific style.

**Code Example**:
```python
social_template = """You are an influencer that, given a story, generate a social media post to promote the story.
The style should reflect the type of social media used.
Story:
{story}
Social media: {social}
Review from a New York Times play critic of the above play:"""

social_prompt_template = PromptTemplate(input_variables=["story", "social"], template=social_template)
social_chain = LLMChain(llm=llm, prompt=social_prompt_template, output_key='post')

post = social_chain({'story': result['story'], 'social': 'Instagram'})
print(post['post'])
```

**Sample Output**:
```plaintext
"John and Sarah's journey of discovery and friendship is a must-see! From the magical world they explore to the obstacles they overcome, this play is sure to leave you with a newfound appreciation for the power of friendship. #FriendshipGoals #AdventureAwaits #MagicalWorlds"
```

### Step 3: Initialize the Image Generator Chain
- **Purpose**: Create a visual representation of the story for social media using DALL·E.

**Code Example**:
```python
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

image_template = """Generate a detailed prompt to generate an image based on the following social media post:
Social media post:
{post}
"""

image_prompt_template = PromptTemplate(input_variables=["post"], template=image_template)
image_chain = LLMChain(llm=llm, prompt=image_prompt_template, output_key='image')
```

**DALL·E Integration**:
```python
from langchain.utilities.dalle_image_generator import DallEAPIWrapper

image_url = DallEAPIWrapper().run(image_chain.run("a cartoon-style cat playing piano"))

# Display the image using OpenCV and skimage
import cv2
from skimage import io

image = io.imread(image_url)
cv2.imshow('image', image)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

**Sample Output**:
An image generated by DALL·E related to the social media post.

### Step 4: Combine the Chains with SequentialChain
- **Purpose**: Execute the story, post generation, and image generation in sequence.

**Code Example**:
```python
from langchain.chains import SequentialChain

overall_chain = SequentialChain(
    input_variables=['topic', 'genre', 'audience', 'social'],
    chains=[story_chain, social_chain, image_chain],
    output_variables=['post', 'image'],
    verbose=True
)

result = overall_chain({
    'topic': 'friendship story',
    'genre': 'adventure',
    'audience': 'young adults',
    'social': 'Instagram'
}, return_only_outputs=True)

print(result['post'])
print(result['image'])
```

**Sample Output**:
```plaintext
{
    'post': "John and Sarah's journey of discovery and friendship is a must-see! From the magical world they explore...",
    'image': 'Prompt: Create a digital drawing of John and Sarah standing side-by-side, surrounded by a magical forest...'
}
```

### Displaying the Image
```python
image_url = DallEAPIWrapper().run(result['image'])
st.image(image_url)
```

## Comparison of Multimodal Implementation Approaches

### Pros and Cons

| Approach                | Flexibility       | Control        | Maintenance    |
|-------------------------|-------------------|-----------------|----------------|
| Agentic (Pre-built)     | High              | Low             | Low             |
| Agentic (Custom Tools)  | Medium            | Medium          | Medium          |
| Hard-coded (Sequential) | Low               | High            | High            |

### Key Considerations
- **Flexibility vs. Control**: The hard-coded approach offers full control over the sequence of actions, whereas agentic approaches provide flexibility and adaptability.
- **Debugging**: The hard-coded method facilitates easier debugging since individual chains can be isolated and tested.
- **Complexity**: The agentic approach reduces the complexity of orchestration but at the cost of less predictability and potential challenges in understanding the sequence of actions.

## Front-End Implementation with Streamlit

### Step 1: Set Up the Webpage
**Code**:
```python
import streamlit as st
from dotenv import load_dotenv
import os

st.set_page_config(page_title="StoryScribe", page_icon="")
st.header(' Welcome to StoryScribe, your story generator and promoter!')

load_dotenv()
openai_api_key = os.environ['OPENAI_API_KEY']
```

### Step 2: Create Input Fields
**Code**:
```python
topic = st.sidebar.text_input("What is the topic?", 'A dog running on the beach')
genre = st.sidebar.text_input("What is the genre?", 'Drama')
audience = st.sidebar.text_input("What is your audience?", 'Young adult')
social = st.sidebar.text_input("What is your social platform?", 'Instagram')
```

### Step 3: Run the Chain and Display Results
**Code**:
```python
if st.button('Create your post!'):
    result = overall_chain({
        'topic': topic,
        'genre': genre,
        'audience': audience,
        'social': social
    }, return_only_outputs=True)

    image_url = DallEAPIWrapper().run(result['image'])
    
    st.subheader('Story')
    st.write(result['story'])
    st.subheader('Social Media Post')
    st.write(result['post'])
    st.image(image_url)
```

**Output**:
- **Generated Story**: Displayed in the 'Story' section.
- **Social Media Post**: Displayed in the 'Social Media Post' section.
- **Generated Image**: Displayed using Streamlit's `st.image()`.

## Summary
### Key Points:
- **SequentialChain** provides explicit control over the flow of execution.
- **Streamlit integration** allows creating a user-friendly front-end for multimodal applications.
- **Customization and Debugging**: Easier with the hard-coded approach as compared to agentic methods.

### Next Steps:
- **Enhance StoryScribe** with additional functionalities like video creation or sound generation.
- **Explore custom LLM tuning** to fine-tune responses for specific tasks or industries.

This completes the detailed notes on building and comparing different approaches to implementing multimodal applications using LangChain, including an end-to-end solution with a front-end in Streamlit.