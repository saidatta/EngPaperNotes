When multiple processes or threads compete for the CPU, a **scheduler** must decide which one to run next. Efficient scheduling improves both performance and user experience. Below, we will explore key concepts related to scheduling algorithms in operating systems.

#### **2.5.1 Introduction to Scheduling**

Scheduling is the process of deciding which process or thread should run at any given time. The goal is to optimize CPU utilization while maintaining responsiveness and fairness.

##### **Key Types of Scheduling Algorithms**:

1. **Non-preemptive Scheduling**:
   - Once a process is given control of the CPU, it keeps running until it voluntarily releases the CPU (e.g., waiting for I/O).
   - **Example**: **First-Come, First-Served (FCFS)**.
   
2. **Preemptive Scheduling**:
   - The operating system can suspend a running process and switch to another, typically using a **time slice** or responding to higher priority tasks.
   - **Example**: **Round-Robin Scheduling**, **Priority Scheduling**.

---

#### **Process Behavior and Scheduling**

Processes are generally classified based on how much they compute versus how much time they spend waiting for I/O. This affects how they should be scheduled:

- **CPU-bound processes**: Spend most of their time computing (long CPU bursts). Example: Video encoding.
- **I/O-bound processes**: Spend most of their time waiting for I/O (short CPU bursts). Example: Reading from a disk.

Scheduling I/O-bound processes promptly helps keep I/O devices busy, maximizing overall system efficiency.

---

#### **Context Switching**

A **context switch** occurs when the scheduler suspends one process and switches to another. This involves saving the state of the current process (registers, program counter, etc.) and loading the state of the new process. Frequent context switches can lead to **overhead**, as they require saving and restoring the process state and invalidating caches.

---

#### **Scheduling Algorithms**

##### **1. First-Come, First-Served (FCFS)**
- **Non-preemptive**: The process that arrives first is executed first. 
- **Advantage**: Simple and fair in the order of arrival.
- **Disadvantage**: May lead to the **convoy effect**, where shorter jobs get stuck waiting behind longer jobs.

##### **2. Shortest Job Next (SJN)**
- **Non-preemptive**: The process with the shortest burst time is executed first.
- **Advantage**: Minimizes average waiting time.
- **Disadvantage**: Requires knowledge of the future (which is usually impossible). May cause **starvation** for long processes.

##### **3. Round-Robin (RR)**
- **Preemptive**: Each process is given a fixed time slice (quantum), and after the time expires, it is preempted and placed at the back of the queue.
- **Advantage**: Fair for all processes and good for time-sharing systems.
- **Disadvantage**: Frequent context switches can introduce overhead if the quantum is too small.

##### **4. Priority Scheduling**
- **Preemptive or Non-preemptive**: Each process is assigned a priority, and the scheduler picks the process with the highest priority.
- **Advantage**: Allows prioritizing important tasks.
- **Disadvantage**: Can cause **starvation** for lower-priority processes, though **aging** techniques can prevent this by gradually increasing the priority of waiting processes.

---

### **Rust Implementation: Simple Round-Robin Scheduler**

Hereâ€™s an example of a simple **Round-Robin (RR) scheduler** in Rust using threads to simulate processes:

```rust
use std::thread;
use std::sync::{Arc, Mutex};
use std::time::Duration;

fn main() {
    let processes = vec![
        ("Process 1", 4), // name and burst time
        ("Process 2", 3),
        ("Process 3", 5),
    ];

    let processes = Arc::new(Mutex::new(processes));

    let quantum = 2; // time slice in seconds
    let processes_clone = Arc::clone(&processes);

    let scheduler = thread::spawn(move || {
        loop {
            let mut procs = processes_clone.lock().unwrap();
            for (name, burst_time) in procs.iter_mut() {
                if *burst_time > 0 {
                    println!("Running {} for {} seconds", name, quantum);
                    thread::sleep(Duration::from_secs(quantum));

                    *burst_time -= quantum;
                    if *burst_time <= 0 {
                        println!("{} has finished.", name);
                    }
                }
            }

            if procs.iter().all(|(_, burst_time)| *burst_time <= 0) {
                break;
            }
        }
    });

    scheduler.join().unwrap();
}
```

##### **Explanation**:
- The **Round-Robin scheduler** runs each process for a fixed **time quantum** (2 seconds).
- It loops through the list of processes, running each one in turn.
- Once a process's burst time is reduced to zero, it is considered finished.

---

### **Conclusion**

- **RCU** is an advanced synchronization method that allows readers to access shared data concurrently without blocking writers

.
- **Scheduling** is a fundamental task of the OS that determines which process runs at any given time, balancing CPU-bound and I/O-bound processes for optimal performance.
- **Scheduling algorithms** like **FCFS**, **SJN**, **RR**, and **Priority Scheduling** each have strengths and weaknesses, depending on the specific workload.

Understanding these concepts is key to building efficient operating systems and high-performance applications.