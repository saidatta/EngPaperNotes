While the concept of processes has been well established, threads are a newer construct that still garners some research interest, especially in the context of concurrency and scalability in modern multi-core systems. Over the years, operating systems have evolved to better handle multiple threads and processes efficiently.

##### **Processes Overview**
- **Processes** are containers for grouping together related resources, such as:
  - Address space
  - Threads
  - Open files
  - Protection permissions
- The basic idea of processes is largely **settled** and understood across operating systems, although different implementations might vary slightly.

##### **Threads Overview**
- **Threads** are lighter-weight units of execution than processes.
- **Threads** have shared resources within a process but maintain their own execution context such as program counter, registers, and stack.
- Research on threads still occurs, particularly regarding:
  - **Core-aware thread management** (e.g., better utilization of cores in multi-core systems)
  - **Scalability**: How well modern OSs (like Linux) handle many threads and cores.

#### **Current Research Areas in Processes and Threads**

1. **Concurrency Bugs and Proof of Correctness**
   - **Concurrency bugs** are a common challenge in multi-threaded programs.
   - Researchers are working on proving correctness in the presence of concurrency in various services such as:
     - **File Systems** (Chajed et al., 2019; Zou et al., 2019)
     - **Distributed Services** (Setty et al., 2018; Li et al., 2019)
   - It is critical to ensure that concurrency bugs donâ€™t arise when multiple threads or processes access shared resources simultaneously.

2. **Avoiding Locks Using RCU (Read-Copy-Update)**
   - Locks are both hard to manage and can cause **performance bottlenecks**.
   - **RCU (Read-Copy-Update)** avoids locks altogether by allowing readers to access data while updates are made by writers in a deferred manner.
   - RCU is widely used in **Linux kernels** and other high-performance systems (McKenney et al., 2013).

3. **Recording and Replaying Process Execution**
   - A crucial area of research is on **recording and replaying** process executions (Viennot et al., 2013).
   - **Replaying** a process can be valuable for:
     - **Debugging**: Allows developers to track down bugs.
     - **Security**: Helps investigate potential security incidents by replaying the exact sequence of events.

4. **Security Vulnerabilities in Modern CPUs**
   - **CPU security vulnerabilities** (such as **Spectre** and **Meltdown**) discovered in 2018 had profound impacts across hardware, OS, and software ecosystems.
   - These vulnerabilities influenced scheduling algorithms, particularly in how CPU cores are shared among different **security domains**.
   - Windows, for example, introduced algorithms to ensure that processes from different security domains do not share the same core (Microsoft, 2018).

5. **Scheduling Research**
   - While traditional scheduling research has slowed, there are still active areas of interest, including:
     - **Cluster Scheduling for Deep Learning** (Xiao et al., 2018)
     - **Microservices Scheduling** (Sriraman, 2018)
     - **Schedulability in real-time systems** (Yang et al., 2018)

#### **Summary of Processes and Threads**

- **Processes** and **threads** provide the foundation for concurrent execution in modern operating systems.
- Threads are lighter-weight units of execution and are often scheduled independently of their parent processes.
- Multiple threads can exist within the same process, sharing memory and file descriptors but having their own stack and registers.
- **Thread Communication** is similar to inter-process communication (IPC) and often utilizes semaphores, monitors, and message passing for synchronization.

##### **Rust Example: Multi-Threaded Scheduling with Mutexes**

```rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    let counter = Arc::new(Mutex::new(0));
    let mut handles = vec![];

    for _ in 0..10 {
        let counter = Arc::clone(&counter);
        let handle = thread::spawn(move || {
            let mut num = counter.lock().unwrap();
            *num += 1;
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!("Result: {}", *counter.lock().unwrap());
}
```

#### **Operating System Process States**
- **Running**: The process is actively executing on the CPU.
- **Runnable**: The process is ready to run but is waiting for CPU time.
- **Blocked**: The process is waiting for an I/O event or other external input.
- Processes can transition between these states, typically managed by the OS scheduler.

---

### **Research on Scheduling Algorithms**

#### **Guaranteed Scheduling**
- Ensures fairness by allocating **1/n** of CPU time to each process when there are **n** processes.
- The **Completely Fair Scheduler (CFS)** in Linux is an example of a scheduler using this principle.
  - **Red-Black Trees** are used to track **spent execution time** and ensure fairness.

#### **Lottery Scheduling**
- **Lottery Scheduling** uses a randomized method to allocate CPU time based on tickets.
- More important processes can receive more tickets, thereby increasing their chance of "winning" CPU time.
  
#### **Fair-Share Scheduling**
- **Fair-Share Scheduling** ensures that users, rather than individual processes, are allocated CPU time.
- This prevents scenarios where one user starts many processes, monopolizing CPU resources.

#### **Scheduling in Real-Time Systems**
- Real-time systems must adhere to **hard** and **soft deadlines**.
  - **Hard real-time**: Missing a deadline is catastrophic.
  - **Soft real-time**: Missing a deadline is undesirable but tolerable.
- Real-time scheduling algorithms ensure that all deadlines are met through careful calculation of system load.

---

#### **Thread Scheduling**

Scheduling in systems that support **user-level** and **kernel-level threads** differs significantly. In user-level thread systems, the OS schedules processes, while the **runtime system** schedules the threads. In kernel-level threads, the OS can schedule individual threads.

##### **User-Level Thread Scheduling**:
- Fast context switches as no kernel intervention is needed.
- Thread scheduling is controlled by the application, giving more flexibility for specialized use cases like web servers.

##### **Kernel-Level Thread Scheduling**:
- The kernel is aware of threads, and context switching occurs between threads, even from different processes.
- The tradeoff is performance, as switching between threads in different processes requires **memory map switches** and **cache invalidation**, which adds overhead.

#### **Equations & Calculations**

1. **Schedulability in Real-Time Systems**:
   \[
   \sum_{i=1}^{m} \frac{C_i}{P_i} \leq 1
   \]
   - \( C_i \) = Computation time for event \( i \)
   - \( P_i \) = Period for event \( i \)
   - This equation checks if the system can handle all periodic events within their respective periods.

2. **Average Wait Time Calculation** (Shortest Job First Scheduling):
   \[
   \text{Average Wait Time} = \frac{4a + 3b + 2c + d}{4}
   \]
   - \( a, b, c, d \) are the execution times for the jobs.

#### **Conclusion**
Research on processes and threads continues to evolve, especially in areas related to **concurrency**, **security**, and **scalability**. Modern challenges such as power efficiency, cloud computing, and real-time system demands are driving new scheduling algorithms and techniques.