Threads are a fundamental concept in modern operating systems that allow multiple threads of control to exist within the same process. Threads share the same address space, making them more lightweight compared to processes. They enable quasi-parallelism within a process and can improve performance, particularly when dealing with I/O-bound operations.

---
#### **2.2.1 Thread Usage**

Threads are beneficial in the following scenarios:

- **Simplified programming models**: When multiple activities need to occur simultaneously, threads simplify the model by allowing concurrent tasks to run in parallel within the same address space.
  
- **Lighter weight than processes**: Threads are faster to create and destroy than processes. Creating a thread is 10–100 times faster than creating a process.

- **I/O-bound operations**: When an application involves both computation and I/O, threads allow the overlap of these activities, boosting performance.

- **Multiple CPUs (real parallelism)**: On systems with multiple CPUs or cores, threads can provide true parallelism, where different threads run on different CPUs simultaneously.

---

#### **Example: Word Processor with Threads**

A typical word processor can be divided into multiple threads to improve its responsiveness. Consider a scenario where the user deletes a sentence from page 1 of an 800-page document. A multi-threaded word processor could handle the following tasks with separate threads:

- **Interactive thread**: Handles user inputs like scrolling and typing.
- **Reformatting thread**: Recomputes the layout of the entire document in the background.
- **Auto-save thread**: Periodically saves the document to disk.

```
+-------------------------------------------------+
|                Word Processor                   |
+-------------------------------------------------+
|          User Interaction Thread                |
|                                                 |
|          Reformatting Thread                    |
|                                                 |
|          Auto-save Thread                       |
+-------------------------------------------------+
```

If the word processor were single-threaded, the user would experience delays whenever the program is busy with reformatting or saving the file.

---
#### **2.2.2 Classical Thread Model**
In the classical model, a **process** groups resources like address space, open files, and other system resources. A **thread** is the unit of execution, and a process may contain multiple threads. Threads share the following:
- **Address space**: All threads in a process share the same memory.
- **Global variables**: Threads share access to global data.
- **Open files**: Threads in the same process can access files opened by other threads.

##### **Per-Thread vs Per-Process Properties**

| **Per-Process Items**         | **Per-Thread Items**         |
|-------------------------------|------------------------------|
| Address space                 | Program counter              |
| Global variables              | Registers                    |
| Open files                    | Stack                        |
| Child processes               | State (running, blocked)     |
| Signals and alarms            |                              |

---

#### **Thread Example in Rust**

Rust’s standard library supports threads through the `std::thread` module. Below is an example simulating a multi-threaded word processor using Rust:

```rust
use std::thread;
use std::time::Duration;

fn main() {
    // Thread for user interaction
    let user_thread = thread::spawn(|| {
        println!("User interaction thread started...");
        thread::sleep(Duration::from_secs(2));
        println!("User interacting...");
    });

    // Thread for background reformatting
    let reformat_thread = thread::spawn(|| {
        println!("Reformatting thread started...");
        thread::sleep(Duration::from_secs(4));
        println!("Reformatting document...");
    });

    // Thread for auto-saving
    let save_thread = thread::spawn(|| {
        println!("Auto-save thread started...");
        thread::sleep(Duration::from_secs(3));
        println!("Document saved...");
    });

    user_thread.join().unwrap();
    reformat_thread.join().unwrap();
    save_thread.join().unwrap();
}
```

In this simulation:
- The `user_thread` simulates user interaction.
- The `reformat_thread` handles background reformatting of the document.
- The `save_thread` simulates periodic auto-saving of the document.

---

#### **2.2.3 Web Server Example Using Threads**

A multithreaded web server is another example of efficient thread usage. It employs the following threads:
- **Dispatcher thread**: Handles incoming requests and assigns them to worker threads.
- **Worker threads**: Process requests by checking the cache for the requested page. If not in the cache, the worker retrieves the page from disk.

```
+--------------------------------------------------+
|              Multithreaded Web Server            |
+--------------------------------------------------+
| Dispatcher Thread | Worker Threads               |
|   (Handles new    |   (Process incoming requests)|
|   requests)       |   (Check cache/disk)         |
+--------------------------------------------------+
```

**Example Web Server Outline in Rust:**

```rust
use std::thread;
use std::sync::{Arc, Mutex};

fn main() {
    let cache = Arc::new(Mutex::new(vec![])); // Shared web page cache

    // Dispatcher thread
    let dispatcher = thread::spawn({
        let cache = Arc::clone(&cache);
        move || {
            for request in 0..10 {
                println!("Dispatcher handling request {}", request);
                let mut cache = cache.lock().unwrap();
                cache.push(format!("Page for request {}", request));
                thread::sleep(std::time::Duration::from_millis(500));
            }
        }
    });

    // Worker threads (simulating multiple worker threads)
    let worker_threads: Vec<_> = (0..3)
        .map(|i| {
            let cache = Arc::clone(&cache);
            thread::spawn(move || {
                for _ in 0..3 {
                    let cache = cache.lock().unwrap();
                    println!("Worker {} processing: {:?}", i, cache);
                    thread::sleep(std::time::Duration::from_millis(500));
                }
            })
        })
        .collect();

    dispatcher.join().unwrap();
    for worker in worker_threads {
        worker.join().unwrap();
    }
}
```

This example simulates a dispatcher thread filling a cache with web pages and worker threads processing requests from the cache.

---

### **Thread States**

Just like processes, threads can be in several states:
- **Running**: Actively using the CPU.
- **Blocked**: Waiting for some event (e.g., I/O completion).
- **Ready**: Ready to run, waiting for the CPU.

The state transitions between threads are similar to those of processes:

```
Blocked ←──────────────→ Ready
      ↑                        ↓
      Running ←→ Scheduler
```

Threads have their own **stack**, which contains the execution history, and **registers** but share the process's address space.

---

#### **Thread Synchronization**

Threads often need to coordinate their actions to avoid conflicts (e.g., reading and writing shared data). This can be managed using synchronization primitives like **Mutexes** or **Channels** in Rust.

**Example of Synchronizing Threads in Rust using Mutex:**

```rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    let counter = Arc::new(Mutex::new(0));

    let handles: Vec<_> = (0..10)
        .map(|_| {
            let counter = Arc::clone(&counter);
            thread::spawn(move || {
                let mut num = counter.lock().unwrap();
                *num += 1;
            })
        })
        .collect();

    for handle in handles {
        handle.join().unwrap();
    }

    println!("Result: {}", *counter.lock().unwrap());
}
```

In this example:
- A **Mutex** protects shared data (`counter`), ensuring that only one thread modifies it at a time.

---

### **Conclusion**

Threads provide a powerful abstraction for enabling concurrency within processes. They allow efficient use of CPU resources by running tasks in parallel, especially in I/O-bound applications. However, they also introduce complexity regarding shared data, synchronization, and system calls like `fork`. In practice, proper thread management and synchronization mechanisms are essential to prevent race conditions and ensure correctness.

By understanding the structure and behavior of threads, you can design highly efficient and responsive applications.